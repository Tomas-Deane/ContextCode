File: .\main.py
===============

"""
Main entry point for the application. A Flask web server that reads data from the
metrics datamodel and returns it as a JSON object while also timing the operation.
This brings together the BlockTimer class and metrics DataReader class from prior
examples (note, DataSnapshot is the new name for the datamodel object).

The metrics route has three different conversion methods to show how to convert the
data to JSON. JSON conversion needs a deep understanding of the data structure being
passed to any given parsing/generation method. The metrics route has a parameter to
demonstrate the three different methods, called conversion_method.

Browse to localhost:<port>/metrics?conversion_method=1 to see the raw JSON string.
Browse to localhost:<port>/metrics?conversion_method=2 to see the JSON string converted to a dict()
Browse to localhost:<port>/metrics?conversion_method=3 to see the object converted directly to a dict()

Note that method 3 is the one that provides the correct results and is also the most 
efficient as it avoids the overhead of converting to a JSON string and then back to a
JSON object.

To use this, run it and browse to the localhost:<port>/metrics route with a conversion method of your choice.
"""
import sys
import json
import logging
from lib_config.config import Config
from lib_utils.blocktimer import BlockTimer
from datetime import datetime, UTC
from lib_metrics_datamodel.metrics_datamodel import *
from flask import Flask, request


class Application:
    def __init__(self):
        """Initialize the application with required configuration and logging."""
        self.config = Config(__file__)
        self.logger = logging.getLogger(__name__)
        self.webserver = Flask(__name__)
        self.setup_routes()
        self.logger.debug("Application initialized")

    def setup_routes(self):
        """Setup the routes for the application."""
        self.webserver.route("/hello")(self.hello_world)
        self.webserver.route("/metrics")(self.metrics)

    def hello_world(self):
        """Hello world route."""
        self.logger.info("Hello world route called")
        return {'message': 'Hello, World from the Data Reading Web Server! Use /metrics to get data.'}

    def metrics(self):
        """Metrics route.
        Query Parameter:
            conversion_method (int, optional): The method of conversion to use. Defaults to 0, which is recommended.
            1: Response contains a RAW JSON string
            2: Object => JSON String => dict() for flask to convert back to JSON
            3: Object direct to dict() for flask to do the only JSON string conversion
        """
        conversion_method = request.args.get('conversion_method', default=0, type=int)
        
        self.logger.info("Metrics route called with conversion method %s", conversion_method)
        # Main application logic executed, with top-level error handling
        try:
            with BlockTimer("read_metrics", self.logger):
                data_snapshot = Device.read_PC_metrics()
                # Three different ways to convert to JSON for REST response
                if conversion_method == 1:
                    # RAW JSON string
                    rest_ready_json = data_snapshot.to_json()                
                elif conversion_method == 2:
                    # Object => JSON String => dict() for flask to convert back to JSON
                    json_string = data_snapshot.to_json()
                    rest_ready_json = json.loads(json_string)                
                else:
                    # Object direct to dict() for flask to do the only JSON string conversion
                    rest_ready_json = data_snapshot.to_dict()
                
                timestamp = datetime.now(UTC).isoformat()
            
            return {
                'status': 'success',
                'data': rest_ready_json,
                'timestamp': timestamp
            }, 200
            
        except Exception as e:
            self.logger.exception("Error in metrics route: %s", str(e))
            return {
                'status': 'error',
                'message': str(e)
            }, 500

    def run(self) -> int:
        """
        Main application logic.
        Returns:
            int: Exit code (0 for success, non-zero for error)
        """
        try:
            self.logger.info("Starting Flask web server on port %s", self.config.web.port)
            self.webserver.run(debug=self.config.web.debug, port=self.config.web.port)
            self.logger.info("Application completed successfully")
            return 0
            
        except Exception as e:
            self.logger.exception("Application failed with error: %s", str(e))
            return 1
        

def main() -> int:
    """Entry point for the application."""
    app = Application()
    return app.run()

if __name__ == "__main__":
    sys.exit(main())


File: .\lib_config\config.py
============================

"""
Library module for configuration and logging setup for the application.
Defines types for the configuration and provides a method to load and setup logging.
Optionally, the working directory can be set to the directory of the calling script
to enable files to be loaded relative to the script without resorting to absolute paths.
"""

import json
import os
from dataclasses import dataclass
from typing import Optional
from typing import Any
import logging
import logging.handlers
import colorlog

@dataclass
class WebConfig:
    host: str
    port: int
    debug: bool

@dataclass
class ConsoleLoggingConfig:
    enabled: bool
    level: str
    format: str
    date_format: str
    def get_level(self) -> int:
        return getattr(logging, self.level.upper())

@dataclass
class FileLoggingConfig(ConsoleLoggingConfig):
    log_dir: str
    filename: str
    max_bytes: int
    backup_count: int

@dataclass
class LoggingConfig:
    console_output: ConsoleLoggingConfig
    file_output: FileLoggingConfig

class Config:
    web: WebConfig
    logging_config: LoggingConfig

    @staticmethod
    def set_working_directory(script_path: str) -> str:
        """
        Sets working directory to the location of the calling script's path as supplied by __file__.
        Can be used to set the working directory to the location in which the config file is found
        without resorting to absolute paths.
        Args:
            script_path: The __file__ value from the calling script.
        Returns:
            The new working directory path
        """
        script_dir = os.path.dirname(os.path.abspath(script_path))
        os.chdir(script_dir)
        return script_dir

    def __init__(self, script_path:str =None, config_path: str = "config.json"):
        """Loads the config for usage elsewhere and sets up logging according to the configuration"""
        if script_path:
            self.set_working_directory(script_path)
        self._config = self._load_config(config_path)
        #Explicitly convert the nested dictionaries to Config objects so they are strongly typed.
        self.web = WebConfig(**self._config.get('web', {}))
        raw_logging_config = self._config.get('logging_config', {})
        self.logging_config = LoggingConfig(
            console_output=ConsoleLoggingConfig(**raw_logging_config.get('console_output', {})),
            file_output=FileLoggingConfig(**raw_logging_config.get('file_output', {}))
        )
        self.setup_logging()

        
        
    def _load_config(self, config_path: str) -> dict:
        if not os.path.exists(config_path):
            raise FileNotFoundError(f"Config file not found: {config_path}")
        with open(config_path, 'r') as f:
            return json.load(f)
    
    def setup_logging(self) -> logging.Logger:
        # Create logs directory if needed and file output is enabled
        if self.logging_config.file_output.enabled:
            os.makedirs(self.logging_config.file_output.log_dir, exist_ok=True)
                
        # Get root logger
        logger = logging.getLogger()

        # Set base filtering to be the lowest of all enabled handlers.
        root_level = logging.NOTSET  # Default if no handlers are enabled (essentially suppresses all messages)
        enabled_levels = []
        if self.logging_config.console_output.enabled:
            enabled_levels.append(self.logging_config.console_output.get_level())
        if self.logging_config.file_output.enabled:
            enabled_levels.append(self.logging_config.file_output.get_level())
        if enabled_levels:
            root_level = min(enabled_levels)        
        logger.setLevel(root_level)

        # Clear any existing handlers
        logger.handlers.clear()
        
        # Add console handler if enabled
        if self.logging_config.console_output.enabled:
            console_handler = logging.StreamHandler()
            console_formatter = colorlog.ColoredFormatter(
            fmt='%(log_color)s' + self.logging_config.console_output.format,
            datefmt=self.logging_config.console_output.date_format,
            reset=True,
            log_colors={
                'DEBUG': 'cyan',
                'INFO': 'green',
                'WARNING': 'yellow',
                'ERROR': 'red',
                'CRITICAL': 'red,bg_white'
            }
            )
            console_handler.setFormatter(console_formatter)
            console_handler.setLevel(self.logging_config.console_output.get_level())
            logger.addHandler(console_handler)
        
        # Add file handler if enabled
        if self.logging_config.file_output.enabled:
            file_path = os.path.join(self.logging_config.file_output.log_dir, self.logging_config.file_output.filename)
            file_handler = logging.handlers.RotatingFileHandler(
                file_path,
                maxBytes=self.logging_config.file_output.max_bytes,
                backupCount=self.logging_config.file_output.backup_count
            )
            file_formatter = logging.Formatter(
                fmt=self.logging_config.file_output.format,
                datefmt=self.logging_config.file_output.date_format
            )
            file_handler.setFormatter(file_formatter)
            file_handler.setLevel(self.logging_config.file_output.get_level())
            logger.addHandler(file_handler)
        
        return logger


File: .\lib_metrics_datamodel\metrics_datamodel.py
==================================================

"""
Library module for the data model for the metrics data.
All data and logic to read and store metrics data from supported devices.
"""

from datetime import datetime
from typing import List
from uuid import UUID
from dataclasses import dataclass, field
from dataclasses_json import dataclass_json
import logging
import psutil
import platform


@dataclass_json
@dataclass
class Metric:
    name: str
    value: float

@dataclass_json
@dataclass 
class Device:
    logger = logging.getLogger(__name__)
    name: str
        
    @staticmethod
    def read_PC_metrics() -> 'DataSnapshot':
        """Creates and returns a new DataSnapshot instance"""
        pc_device_name = platform.node()
        device = Device(name=pc_device_name)
        data_snapshot = DataSnapshot(device)

        Device.logger.info("Reading data from local device %s", device.name)
        
        num_system_threads = 0
        num_processes = 0
        for process in psutil.process_iter(['num_threads', 'name']):
            try:
                thread_count = process.num_threads()
                Device.logger.debug("Process %s(%d) has %d threads", process.name(), process.pid, thread_count)
                num_system_threads += thread_count
                num_processes += 1
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                # Skip processes we can't access
                continue
        
        Device.logger.info("#System Threads: %d across %d processes", num_system_threads, num_processes)
        data_snapshot.metrics.append(Metric(name="num_system_threads", value=num_system_threads))
        data_snapshot.metrics.append(Metric(name="num_processes", value=num_processes))
   
        memory = psutil.virtual_memory()
        used_ram_mb = memory.used / (1024 * 1024)  # Convert bytes to MB
        total_ram_mb = memory.total / (1024 * 1024)
        ram_percent = memory.percent
        
        Device.logger.info("RAM Usage: %.2f MB / %.2f MB (%.1f%%)", used_ram_mb, total_ram_mb, ram_percent)
        data_snapshot.metrics.append(Metric(name="used_ram_mb", value=used_ram_mb))
        data_snapshot.metrics.append(Metric(name="total_ram_mb", value=total_ram_mb))
        data_snapshot.metrics.append(Metric(name="ram_percent", value=ram_percent))

        return data_snapshot

@dataclass_json
@dataclass
class DataSnapshot:
    logger = logging.getLogger(__name__)

    device: Device = None
    timestamp: datetime = field(default_factory=datetime.now)
    metrics: List[Metric] = field(default_factory=list)
 


File: .\lib_utils\blocktimer.py
===============================

"""
Library module for utility functions for the application.
BlockTimer is a RAII timer that measures and logs execution time of a code block.

Does have test code to demonstrate usage at the bottom of the file.
"""
import time
import logging

class BlockTimer:
    """RAII timer that measures and logs execution time of a code block."""
    
    def __init__(self, block_name: str, logger: logging.Logger):
        """Initialize the timer with a name for the code block being timed.
        
        Args:
            block_name (str): Name to identify this timed block in logs
            logger (logging.Logger): Logger instance to use for output
        """
        self.block_name = block_name
        self.logger = logger
        
    def __enter__(self):
        """Start timing when entering the context."""
        self.start_time = time.perf_counter_ns()
        return self
        
    def __exit__(self, exc_type, exc_val, exc_tb):
        """Log the elapsed time when exiting the context."""
        end_time = time.perf_counter_ns()
        duration_ms = (end_time - self.start_time) / 1_000_000  # Convert ns to ms
        self.logger.info("%s took %.2fms to execute", self.block_name, duration_ms)


if __name__ == "__main__":
    with BlockTimer("main", logging.getLogger(__name__)) as timer:
        print("No timing since no logger setup in the test")


